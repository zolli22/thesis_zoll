---
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = F, warning = F, tidy = TRUE, tidy.opts = list(blank = FALSE, width.cutoff = 60))
```

```{r, echo = F}
species_pal <- c("#219EBC", "#023047", "#FFB703", "#FB8500", "#586f7c")

health_pal <- c("#83b692", "#f9ada0", "#f9627d", "#586f7c")

method_pal <- c("#FBCF9D", "#7dcfb6", "#f79256")
```

# Results {#results}

## Canopy Width and Tree Height Model

I used a third order polynomial regression to predict both tree height and crown width from tree DBH. In order to account for expected differences between species, I included species as an interaction term. I chose a third order polynomial because it not only encapsulated the relationship between DBH and tree height as well as DBH and canopy width, but it also was the most accurate when modeling the individual species. While the 
The tree height model has an adjusted R-squared value of 0.78, and a P-value of < 2.2e-16 (Figure \@ref(fig:height-model)). The crown width model has an adjusted R-squared value of 0.72, and a P-value of < 2.2e-16 (Figure \@ref(fig:width-model-g), \@ref(tree-model-eqs)).

```{r tree-model, include = F, tidy = T}
# load park data, filter to relevant species, and get average crown width.
my_park <- pdxTrees::get_pdxTrees_parks() %>%
  filter(Species %in% c('ACPL', 'THPL', 'PSME', 'ACMA')) %>%
  mutate(crown_width = (Crown_Width_EW+Crown_Width_NS)/2)

# create model for heights
heights <- lm(Tree_Height ~ poly(DBH, degree = 3, raw = T) * Species, data = my_park)

# create model for crown width
cr_width <- lm(crown_width ~ poly(DBH, degree = 3, raw = T) * Species, data = my_park)

# load street data, filter to relevant species
my_street <- pdxTrees::get_pdxTrees_streets() %>%
  filter(Species %in% c('ACPL', 'THPL', 'PSME', 'ACMA'))

# run street trees through both models
my_street <- my_street %>%
  mutate(width_preds = predict(cr_width, my_street, se.fit = FALSE), 
         height_preds = predict(heights, my_street, se.fit = F))

# export data file
# write_csv(my_street, "my_street.csv")

# graphing
p_height_model <- my_park %>% 
  ggplot(aes(x = sqrt(DBH), y = Tree_Height, color = Species)) +
  geom_point(alpha = .1)+
  scale_color_manual(values = species_pal)+
  geom_smooth(method = "lm", se = F, formula = y ~ poly(x, degree = 3, raw = T))+
  labs(subtitle = "Park trees", y = "Tree Height Measurement")+
  guides(color = "none")

p_width_model <- my_park %>% 
  ggplot(aes(x = sqrt(DBH), y = crown_width, color = Species)) +
  geom_point(alpha = .1)+
  scale_color_manual(values = species_pal)+
  geom_smooth(method = "lm", se = F, formula = y ~ poly(x, degree = 3, raw = T))+
  labs(subtitle = "Park trees", y = "Canopy Width Measurement")+
  guides(color = "none")

s_height_preds <- my_street %>% 
  ggplot(aes(x = sqrt(DBH), y = height_preds, color = Species)) +
  geom_point(alpha = .3)+
  scale_color_manual(values = species_pal)+
  labs(subtitle = "Street trees", y = "Tree Height Prediction")

s_width_preds <- my_street %>% 
  ggplot(aes(x = sqrt(DBH), y = width_preds, color = Species)) +
  geom_point(alpha = .3)+
  scale_color_manual(values = species_pal)+
  labs(subtitle = "Street trees", y = "Canopy Width Prediction")
```

```{r height-model, echo = F, fig.scap="Tree height predictive model", out.width= "80%", fig.cap = "Predictive model for tree height from measured DBH. A third order polynomial regression was used in order to account for the variation between species. (Adjusted R-squared = 0.72, P <2.2e-16)"}
p_height_model + s_height_preds 
```

```{r width-model-g, echo = F, fig.scap="Crown width predictive model", out.width = "80%", fig.cap = "Third order polynomial model for predicting tree crown width based on measured DBH and species, with predictions for street trees. (R-squared = 0.72,  P <2.2e-16)"}
p_width_model + s_width_preds
```

## Point Method

```{r, include = F, message = F, warning = F}
cnh_point <- read_csv("data/cnh_point.csv") %>%
  mutate(health_rat = fct_relevel(health_rat, levels = c("poor", "fair", "good"))) %>%
  filter(!is.na(health_rat)) %>%
  mutate(tree_type = case_when(species == "ACMA" ~ "broadleaf",
                               species == "ACPL" ~ "broadleaf",
                               TRUE ~ "conifer"))
```

With the selection of CNH trees and 2021 NDVI data, a statistical analysis of the point value method shows that there is a statistically significant difference in the average NDVI values between health categorizations of "Fair" and "Good" (ANOVA, $F_{2, 109} = 3.892$, $P = 0.023$, TukeyHSD). There is a general positive correlation between NDVI and health category, specifically Fair and Good. The relationship between health and NDVI is more apparent in the two maple species, but still holds in the "fair" and "good" categories in the two coniferous species (Figure \@ref(fig:point-species)). 

```{r, include = F}
summary(aov(sample_ndvi ~ health_rat, data = cnh_point))
TukeyHSD(aov(sample_ndvi ~ health_rat, data = cnh_point))
```

```{r point-species, echo = F, out.width = "100%", fig.scap = "Point Method NDVI and Health Rating, by Species", fig.cap="NDVI extracted for CNH trees using the point method compared to CNH tree health categorization. There is a statistically significant difference between Fair and Good (ANOVA, $F_{2, 109} = 3.892$, $P = 0.023$, TukeyHSD)"}
cnh_point %>%
  ggplot(aes(x = health_rat, y = sample_ndvi))+
  scale_color_manual(values = species_pal)+
  geom_boxplot()+
  geom_point(aes(color = species), alpha = .2, size = 3)+
  facet_wrap(~species)+
  labs(x = "Health Rating", y = "Mean NDVI")
```


## Radius Method

```{r, include = F, message = F, warning = F}
cnh_radius <- read_csv("data/cnh_radius.csv") %>%
  mutate(health_rat = fct_relevel(health_rat, levels = c("poor", "fair", "good"))) %>%
  filter(!is.na(health_rat)) %>%
  mutate(tree_type = case_when(species == "ACMA" ~ "broadleaf",
                               species == "ACPL" ~ "broadleaf",
                               TRUE ~ "conifer"))
```

With the radius method of pixel selection and crown delineation, there is a statistically significant difference in the mean NDVI values for health categories (ANOVA, $F_{2,109}=4.923$, $P = 0.0089$; TukeyHSD: good-poor $P = 0.033$, good-fair $P = 0.014$). Similar to the point method, there is a larger difference in average NDVI between the "fair" and "good" categories than "poor" and "fair", and with the radius method, this is now a statistically significant difference (Figure \@ref(fig:radius-species)). 

```{r, include = F}
summary(aov(sample_ndvi ~ health_rat, data = cnh_radius))
TukeyHSD(aov(sample_ndvi ~ health_rat, data = cnh_radius))
```

```{r radius-species, echo = F, fig.scap = "Radius method mean NDVI and health condition by species", fig.cap = "Boxplot of average NDVI from radius method and health condition, by species. The relationship berween NDVI and health category is strongest in the maples, but still somewhat aparent in the conifers. (ANOVA, $F_{2,109}=4.923$, $P = 0.0089$; TukeyHSD: good-poor $P = 0.033$, good-fair $P = 0.014$)", out.width = "100%"}
cnh_radius %>%
  ggplot(aes(x = health_rat, y = sample_ndvi))+
  scale_color_manual(values = species_pal)+
  geom_boxplot()+
  geom_point(aes(color = species), alpha = .2, size = 3)+
  facet_wrap(~species)+
  theme_minimal()+
  labs(x = "Health Rating", y = "Mean NDVI")
```

## LiDAR Method

```{r, include = F, message = F, warning = F}
cnh_lidar <- read_csv("data/cnh_lidar.csv") %>%
  mutate(health_rat = fct_relevel(health_rat, levels = c("poor", "fair", "good"))) %>%
  filter(!is.na(health_rat)) %>%
  mutate(tree_type = case_when(species == "ACMA" ~ "broadleaf",
                               species == "ACPL" ~ "broadleaf",
                               TRUE ~ "conifer"))
```

There is a statistically significant difference in NDVI between health categories for the LiDAR method, specifically between good and fair (ANOVA, $F_{2,101} = 5.405$, $P = 0.00589$, TukeyHSD). The same relationship between NDVI and health condition for the maples that was seen in the point and radius method is seen here (Figure \@ref(fig:lidar-species)). 

```{r, include = F}
summary(aov(sample_ndvi ~ health_rat, data = cnh_lidar))
TukeyHSD(aov(sample_ndvi ~ health_rat, data = cnh_lidar))
```

```{r lidar-species, echo = F, out.width = "100%", fig.scap = "NDVI and health condition for LiDAR method", fig.cap = "Boxplot of average NDVI from LiDAR method and health condition for each species. Due to the nature of the LiDAR delineation algorithm, no crown was detected for the PSME individual with a poor health rating. The difference between good and fair average NDVIs is statistically significant (ANOVA, $F_{2,101} = 5.405$, $P = 0.00589$, TukeyHSD)"}
cnh_lidar %>%
  ggplot(aes(x = health_rat, y = sample_ndvi))+
  scale_color_manual(values = species_pal)+
  geom_boxplot()+
  geom_point(aes(color = species), alpha = .2, size = 3)+
  facet_wrap(~species)+
  theme_minimal()+
  labs(x = "Health Rating", y = "Mean NDVI")
```

Another aspect of the LiDAR delineation method is the potential for data loss. Five ACMA and three PSME individuals were lost in the LiDAR crown delineation process. If this was with a very large sample size the data loss would likely not be detrimental but especially with a sample size such as mine, a loss of eight trees is a loss of 5% of the total data, 17% loss for ACMA, and 12% loss for THPL.  

## Method Comparison

There is a statistically significant difference in NDVI values for the three different pixel selection methods (ANOVA, $F_{2, 325}=517.8$, $P < 2e-16$; TukeyHSD, radius-point $P = 0.00$, lidar-point $P = 0.00$). When the species are clumped, the three methods show very similar patterns, though the NDVI values are higher for the point method than either of the other two methods (Figure \@ref(fig:methods-all-species)). When all three methods are compared along with species, we can see that the general trend of health rating and NDVI is consistent within each species, but varies across methods (Figure \@ref(fig:methods-species)). Additionally, the pattern between health rating and NDVI is also very similar between trees of the same functional type. Because of the similarities in health patter, I included additional testing examining the difference in species specificity addition versus functional type separation.

```{r, include = F}
cnh_long <- cnh_point %>%
  bind_rows(cnh_radius) %>%
  bind_rows(cnh_lidar)

summary(aov(sample_ndvi ~ method, data = cnh_long))
TukeyHSD(aov(sample_ndvi ~ method, data = cnh_long))
```

```{r methods-all-species, echo = F, out.width = "80%", fig.scap = "NDVI and health rating comparison across methods", fig.cap = "Average NDVI values from all three pixel selection methods with CNH health rating. There is a statistically significant difference in mean NDVI between point and both radius and lidar methods. (ANOVA, $F_{2, 325}=517.8$, $P = <2e-16$, TukeyHSD: radius-point $P = 0.00$, lidar-point $P = 0.00$)"}
cnh_long %>%
  ggplot(aes(y = sample_ndvi, x = health_rat, color = method))+
  scale_color_manual(values = method_pal)+
  geom_boxplot()+
  facet_wrap(~method)+
  labs(x = "Health categorization", y = "Sample NDVI")+
  guides(color = "none")
```

```{r methods-species, echo = F, fig.scap = "Average NDVI comparison between species and methods.", fig.cap = "Average NDVI for each health category, split by tree species and pixel selection method. The general trends remain the same within species, but vary among pixel selection methods."}
cnh_long %>%
  ggplot(aes(y = sample_ndvi, x = health_rat, color = species))+
  scale_color_manual(values =species_pal)+
  geom_boxplot()+
  facet_grid(rows = vars(species), cols = vars(method))+
  labs(x = "Health categorization", y = "Sample NDVI")+
  guides(color = "none")
```

Another important factor to consider when comparing the three pixel selection methods is the amount of pixels used in the NDVI analysis. For the point method, each NDVI value is based off one singular point. 

```{r}
radius_sample_data <- read_csv("data/radius_sample_data.csv") %>%
  dplyr::select(-4, -5) %>% 
  mutate(method = "radius")

lidar_sample_data <- read_csv("data/lidar_sample_data.csv") %>%
  dplyr::select(-4) %>%
  mutate(method = "LiDAR")

count_sample_data <- lidar_sample_data %>%
  bind_rows(radius_sample_data)

ggplot(data = count_sample_data, aes(x = method, y=ndvi_count, color = species))+
  geom_boxplot(outlier.shape=NA)+
  geom_point(position=position_jitterdodge(jitter.width = .1), alpha = .3)+
  scale_color_manual(values = species_pal)+
  labs(x = "Pixel selection method", y = "Pixel count", color = "Tree species")


ggplot(data = count_sample_data, aes(x = ndvi_mean, y=ndvi_count, color = species))+
  geom_point()+
  scale_color_manual(values = species_pal)+
  labs(x = "Average NDVI", y = "Pixel count", color = "Tree species")
```



## Predictive Model

```{r point-modeling, include = F}
point_all <- polr(health_rat~sample_ndvi, Hess = TRUE, data = cnh_point)
point_all_preds <- predict(point_all, cnh_point)
cfm_p_all <- confusionMatrix(point_all_preds, cnh_point$health_rat)
p_all <- ggplotConfusionMatrix(cfm_p_all)+
  labs(subtitle = "health rating ~ NDVI")

brant::brant(point_all)

point_type <- polr(health_rat~sample_ndvi*tree_type, Hess = TRUE, data = cnh_point)
point_type_preds <- predict(point_type, cnh_point)
cfm_p_type <- confusionMatrix(point_type_preds, cnh_point$health_rat)
p_type <- ggplotConfusionMatrix(cfm_p_type)+
  labs(subtitle = "health rating ~ NDVI * tree type")

brant::brant(point_type)

point_species<- polr(health_rat~sample_ndvi*species, Hess = TRUE, data = cnh_point)
point_species_preds <- predict(point_species, cnh_point)
cfm_p_species <- confusionMatrix(point_species_preds, cnh_point$health_rat)
p_species <- ggplotConfusionMatrix(cfm_p_species)+
  labs(subtitle = "health rating ~ NDVI * species")

brant::brant(point_species)
```

In order to determine the impact of differentiating by species in predictive models, I ran three different models for each point selection method, moving from least to most specific: a model that only uses NDVI to predict health rating, a model that includes functional tree type as an interaction term, and a third model that includes species as an interaction term. Due to the limited sample size of the data I am working with, the following models are trained and tested on the same data. If it were to work perfectly, the model would correctly predict the health condition of a CNH tree 100% of the time. The data I use is not perfect, and the models are not perfect either. However, they are likely an idealized version of how model testing and training would work in reality. 
With the point method data, the first model with no interaction term led to all tree points being rated as "Fair". The addition of tree type as an interaction term led to an increase in predictions of "good" health trees, and increased kappa from 0% to 15%. The overall accuracy only increased by 2%, but kappa is more informative in terms of model validity than the accuracy score. Using tree species instead of tree type further improved the kappa of the model. The number of "good" trees that were correctly predicted increased from 7 to 13, but additionally the number of "fair" trees that were correctly predicted dropped from 64 to 59, with the new predictions as "good". (Figure \@ref(point-model-split)). None of these models with the point method were able to correctly predict any trees with poor health categorization.


```{r point-model-split, echo = F, out.width = "90%", fig.scap = "Confusion Matrix results for Point Method models"}
(p_all + p_type + p_species) + 
  plot_annotation(tag_levels = "a", tag_suffix = ")", title = "Point method") + 
  plot_layout(ncol = 2)
```

```{r radius-modeling, include = F}
radius_all <- polr(health_rat~sample_ndvi, Hess = TRUE, data = cnh_radius)
radius_all_preds <- predict(radius_all, cnh_radius)
cfm_r_all <- confusionMatrix(radius_all_preds, cnh_radius$health_rat)
r_all <- ggplotConfusionMatrix(cfm_r_all)+
  labs(subtitle = "health rating ~ NDVI")

radius_type <- polr(health_rat~sample_ndvi*tree_type, Hess = TRUE, data = cnh_radius)
radius_type_preds <- predict(radius_type, cnh_radius)
cfm_r_type <- confusionMatrix(radius_type_preds, cnh_radius$health_rat)
r_type <- ggplotConfusionMatrix(cfm_r_type)+
  labs(subtitle = "health rating ~ NDVI * tree type")

radius_species <- polr(health_rat~sample_ndvi*species, Hess = TRUE, data = cnh_radius)
radius_species_preds <- predict(radius_species, cnh_radius)
cfm_r_species <- confusionMatrix(radius_species_preds, cnh_radius$health_rat)
r_species <- ggplotConfusionMatrix(cfm_r_species)+
  labs(subtitle = "health rating ~ NDVI * species")
```

The radius method was slightly more successful than the point method for the model, with all three method models performing better than those for the point method. From just NDVI to NDVI * tree type, there was an increase in 9 trees to good ratings. Including no species or tree type specification in the predictive model still seems to perform the worst of the three models. The main takeaway from the radius method models is that with the inclusion of species as an interaction term with the radius data, we see our first predictions of the "poor" category. The radius method does involve more pixels than the point method, and with the range in NDVI values being lower than that of the point method it makes sense that there is an increase in "poor" rated trees. However, out of the 15 reference trees with health ratings of "poor", only one was correctly predicted as such (Figure \@ref(fig:radius-model-split)).

```{r radius-model-split, echo = F, fig.scap = "Confusion matrixes for Radius data model", fig.cap = "Confusion matrixes for each species predictions with radius method data"}
(r_all + r_type + r_species) + 
  plot_annotation(tag_levels = "a", tag_suffix = ")", title = "Radius method") + 
  plot_layout(ncol = 2)
```

```{r lidar-modeling, include = F}
lidar_all <- polr(health_rat~sample_ndvi, Hess = TRUE, data = cnh_lidar)
lidar_all_preds <- predict(lidar_all, cnh_lidar)
cfm_l_all <- confusionMatrix(lidar_all_preds, cnh_lidar$health_rat)
l_all <- ggplotConfusionMatrix(cfm_l_all)+
  labs(subtitle = "health rating ~ NDVI")

lidar_type <- polr(health_rat~sample_ndvi*tree_type, Hess = TRUE, data = cnh_lidar)
lidar_type_preds <- predict(lidar_type, cnh_lidar)
cfm_l_type <- confusionMatrix(lidar_type_preds, cnh_lidar$health_rat)
l_type <- ggplotConfusionMatrix(cfm_l_type)+
  labs(subtitle = "health rating ~ NDVI * tree type")

lidar_species <- polr(health_rat~sample_ndvi*species, Hess = TRUE, data = cnh_lidar)
lidar_species_preds <- predict(lidar_species, cnh_lidar)
cfm_l_species <- confusionMatrix(lidar_species_preds, cnh_lidar$health_rat)
l_species <- ggplotConfusionMatrix(cfm_l_species)+
  labs(subtitle = "health rating ~ NDVI * species")
```

The LiDAR data was the most effective out of the three methods at predicting tree health, but also had the only occurance of a "good" tree being predicted as "poor". 

```{r lidar-model-split, echo = F}
(l_all + l_type + l_species) + 
  plot_annotation(tag_levels = "a", tag_suffix = ")", title = "LiDAR method") + 
  plot_layout(ncol = 2)
```

A predictive model was also run with all species together, but with species as an interaction term in the formula. This showed better results than when the species were split, but it seems that most of that is due to increased overall sample size. 

Due to the variation in sample sizes for each health condition category, I sampled down the data so each health category had the same number of points. This improved the results of the model by a lot. 

Given the uneven number of data points available for the varying health conditions, I down-sampled each health category to the smallest number of points in a given category (point = 15, radius = 15, LiDAR = 13). When the predictive models were ran with the even category sizes, the results were statistically significant for all three pixel selection models. For the poi

```{r downsample-test, include = F}
test_data_point <- cnh_long %>%
  filter(method == "point") %>%
  group_by(health_rat) %>%
  sample_n(15)

test_point <- polr(health_rat~sample_ndvi*species, Hess = TRUE, data = test_data_point) 
preds_point <- predict(test_point, test_data_point)
cfm_point <- confusionMatrix(preds_point, test_data_point$health_rat)
gg_point <- ggplotConfusionMatrix(cfm_point)  +
  labs(subtitle = "Point method")

test_data_radius <- cnh_long %>%
  filter(method == "radius") %>%
  group_by(health_rat) %>%
  sample_n(15)

test_radius <- polr(health_rat~sample_ndvi*species, Hess = TRUE, data = test_data_radius) 
preds_radius <- predict(test_radius, test_data_radius)
cfm_radius <- confusionMatrix(preds_radius, test_data_radius$health_rat)
gg_radius <- ggplotConfusionMatrix(cfm_radius)  +
  labs(subtitle = "Radius method")

test_data_lidar <- cnh_long %>%
  filter(method == "lidar") %>%
  group_by(health_rat) %>%
  sample_n(13)

test_lidar <- polr(health_rat~sample_ndvi*species, Hess = TRUE, data = test_data_lidar) 
preds_lidar <- predict(test_lidar, test_data_lidar)
cfm_lidar <- confusionMatrix(preds_lidar, test_data_lidar$health_rat)
gg_lidar <- ggplotConfusionMatrix(cfm_lidar)  +
  labs(subtitle = "LiDAR method")
```

```{r, echo = F, }
gg_point + gg_radius + gg_lidar +
  plot_layout(ncol = 2)
```
